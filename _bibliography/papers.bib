---
---

@string{aps = {American Physical Society,}}

@inproceedings{
  title={Exploring Robustness of GNN against Universal Injection Attack from a Worst-case Perspective},
  author={Dandan Ni and Sheng Zhang and Cong Deng and Han Liu and Gang Chen and Minhao Cheng and Hongyang Chen.},
  booktitle={Proceedings of the 33th ACM International Conference on Information and Knowledge Management},      
  series={CIKM'24},
  selected = true,
  year={2024}
}

@article{wanghaosen,
  title={Unsupervised Heterogeneous Graph Rewriting Attack via Node Clustering},
  author={Haosen Wang, Can Xu, Chenglong Shi, PengFei Zheng, Shiming Zhang, Minhao Cheng, Hongyang Chen},
  journal={ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)},
  selected = true,
  year={2024}
}

@article{Xu_Wang_Wang_Zheng_Chen_2024, 
  title={Geometric-Facilitated Denoising Diffusion Model for 3D Molecule Generation}, 
  volume={38}, 
  url={https://ojs.aaai.org/index.php/AAAI/article/view/27787}, 
  DOI={10.1609/aaai.v38i1.27787}, 
  abstract={Denoising diffusion models have shown great potential in multiple research areas. Existing diffusion-based generative methods on de novo 3D molecule generation face two major challenges. Since majority heavy atoms in molecules allow connections to multiple atoms through single bonds, solely using pair-wise distance to model molecule geometries is insufficient. Therefore, the first one involves proposing an effective neural network as the denoising kernel that is capable to capture complex multi-body interatomic relationships and learn high-quality features. Due to the discrete nature of graphs, mainstream diffusion-based methods for molecules heavily rely on predefined rules and generate edges in an indirect manner. The second challenge involves accommodating molecule generation to diffusion and accurately predicting the existence of bonds. In our research, we view the iterative way of updating molecule conformations in diffusion process is consistent with molecular dynamics and introduce a novel molecule generation method named Geometric-Facilitated Molecular Diffusion (GFMDiff). For the first challenge, we introduce a Dual-track Transformer Network (DTN) to fully excevate global spatial relationships and learn high quality representations which contribute to accurate predictions of features and geometries. As for the second challenge, we design Geometric-facilitated Loss (GFLoss) which intervenes the formation of bonds during the training period, instead of directly embedding edges into the latent space. Comprehensive experiments on current benchmarks demonstrate the superiority of GFMDiff.}, 
  number={1}, 
  journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
  author={Xu, Can and Wang, Haosen and Wang, Weigang and Zheng, Pengfei and Chen, Hongyang}, 
  year={2024}, 
  month={Mar.}, 
  selected = true,
  pages={338-346} 
}

@article{zhang2024collaborate,
  title={Collaborate to Adapt: Source-Free Graph Domain Adaptation via Bi-directional Adaptation},
  author={Zhang, Zhen and Liu, Meihan and Wang, Anhui and Chen, Hongyang and Li, Zhao and Bu, Jiajun and He, Bingsheng},
  journal={arXiv preprint arXiv:2403.01467},
  selected = true,
  year={2024}
}

@inproceedings{10.1145/3511808.3557481,
  author = {Liang, Yuxuan and Ouyang, Kun and Wang, Yiwei and Liu, Xu and Chen, Hongyang and Zhang, Junbo and Zheng, Yu and Zimmermann, Roger},
  title = {TrajFormer: Efficient Trajectory Classification with Transformers},
  year = {2022},
  isbn = {9781450392365},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3511808.3557481},
  doi = {10.1145/3511808.3557481},
  abstract = {Transformers have been an efficient alternative to recurrent neural networks in many sequential learning tasks. When adapting transformers to modeling trajectories, we encounter two major issues. First, being originally designed for language modeling, transformers assume regular intervals between input tokens, which contradicts the irregularity of trajectories. Second, transformers often suffer high computational costs, especially for long trajectories. In this paper, we address these challenges by presenting a novel transformer architecture entitled TrajFormer. Our model first generates continuous point embeddings by jointly considering the input features and the information of spatio-temporal intervals, and then adopts a squeeze function to speed up the representation learning. Moreover, we introduce an auxiliary loss to ease the training of transformers using the supervision signals provided by all output tokens. Extensive experiments verify that our TrajFormer achieves a preferable speed-accuracy balance compared to existing approaches.},
  booktitle = {Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
  pages = {1229–1237},
  numpages = {9},
  keywords = {trajectory classification, transformer, urban computing},
  location = {Atlanta, GA, USA},
  selected = true,
  series = {CIKM '22}
}

@inproceedings{10.1145/3514221.3520150,
  author = {Tang, Jiawei and Luo, Yuyu and Ouzzani, Mourad and Li, Guoliang and Chen, Hongyang},
  title = {Sevi: Speech-to-Visualization through Neural Machine Translation},
  year = {2022},
  isbn = {9781450392495},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3514221.3520150},
  doi = {10.1145/3514221.3520150},
  abstract = {Data visualization is a powerful tool for understating information through visual cues. However, allowing novices to create visualization artifacts for what they want to see is not easy, just as not everyone can write SQL queries. Arguably, the most natural way to specify what to visualize is through natural language or speech, similar to our daily search on Google or Apple Siri, leaving to the system the task of reasoning about what to visualize and how.In this demo, we present Sevi an end-to-end data visualization system that acts as a virtual assistant to allow novices to create visualizations through either natural language or speech. Sevi is powered by two main components: Speech2Text which is based on Google Cloud Speech-to-Text Rest API, and Text2VIS, which uses an end-to-end neural machine translation model called ncNet trained using a cross-domain benchmark called nvBench. Both ncNet and nvBench have been developed by us. We will walk the audience through two general domain datasets, one related to COVID-19 and the other on NBA player statistics, to highlight how Sevi enables novices to easily create data visualizations. Because nvBench contains Text2VIS training samples from 105 domains (e.g., sport, college, hospital, etc.), the audience can play with speech or text input with any of these domains.},
  booktitle = {Proceedings of the 2022 International Conference on Management of Data},
  pages = {2353–2356},
  numpages = {4},
  keywords = {speech-to-visualization, natural language-to-visualization},
  location = {Philadelphia, PA, USA},
  selected = true,
  series = {SIGMOD '22}
}

@article{10.1093/bib/bbac494,
    author = {Liu, Qiao and Zeng, Wanwen and Zhang, Wei and Wang, Sicheng and Chen, Hongyang and Jiang, Rui and Zhou, Mu and Zhang, Shaoting},
    title = "{Deep generative modeling and clustering of single cell Hi-C data}",
    journal = {Briefings in Bioinformatics},
    volume = {24},
    number = {1},
    pages = {bbac494},
    year = {2022},
    month = {12},
    abstract = "{Deciphering 3D genome conformation is important for understanding gene regulation and cellular function at a spatial level. The recent advances of single cell Hi-C technologies have enabled the profiling of the 3D architecture of DNA within individual cell, which allows us to study the cell-to-cell variability of 3D chromatin organization. Computational approaches are in urgent need to comprehensively analyze the sparse and heterogeneous single cell Hi-C data. Here, we proposed scDEC-Hi-C, a new framework for single cell Hi-C analysis with deep generative neural networks. scDEC-Hi-C outperforms existing methods in terms of single cell Hi-C data clustering and imputation. Moreover, the generative power of scDEC-Hi-C could help unveil the differences of chromatin architecture across cell types. We expect that scDEC-Hi-C could shed light on deepening our understanding of the complex mechanism underlying the formation of chromatin contacts.}",
    issn = {1477-4054},
    doi = {10.1093/bib/bbac494},
    url = {https://doi.org/10.1093/bib/bbac494},
    selected = true,
    eprint = {https://academic.oup.com/bib/article-pdf/24/1/bbac494/48783201/bbac494.pdf},
}


@ARTICLE{9956738,
  author={Liang, Yuxuan and Ouyang, Kun and Wang, Yiwei and Pan, Zheyi and Yin, Yifang and Chen, Hongyang and Zhang, Junbo and Zheng, Yu and Rosenblum, David S. and Zimmermann, Roger},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Mixed-Order Relation-Aware Recurrent Neural Networks for Spatio-Temporal Forecasting}, 
  year={2023},
  volume={35},
  number={9},
  pages={9254-9268},
  keywords={Sensors;Forecasting;Atmospheric modeling;Predictive models;Kinetic theory;Data models;Air quality;Physics-informed neural networks;reaction kinetics;spatio-temporal data mining;urban computing},
  selected=true,
  doi={10.1109/TKDE.2022.3222373}
}

@article{luo2022deep,
    title={Deep graph level anomaly detection with contrastive learning},
    author={Luo, Xuexiong and Wu, Jia and Yang, Jian and Xue, Shan and Peng, Hao and Zhou, Chuan and Chen, Hongyang and Li, Zhao and Sheng, Quan Z},
    journal={Scientific Reports},
    volume={12},
    number={1},
    pages={19867},
    year={2022},
    selected = true,
    publisher={Nature Publishing Group UK London}
}

@inproceedings{10.1609/aaai.v37i11.26553,
	author = {Liu, Han and Xu, Zhi and Zhang, Xiaotong and Xu, Xiaoming and Zhang, Feng and Ma, Fenglong and Chen, Hongyang and Yu, Hong and Zhang, Xianchao},
	title = {SSPAttack: a simple and sweet paradigm for black-box hard-label textual adversarial attack},
	year = {2023},
	isbn = {978-1-57735-880-0},
	publisher = {AAAI Press},
	url = {https://doi.org/10.1609/aaai.v37i11.26553},
	doi = {10.1609/aaai.v37i11.26553},
	abstract = {Hard-label textual adversarial attack is a challenging task, as only the predicted label information is available, and the text space is discrete and non-differentiable. Relevant research work is still in fancy and just a handful of methods are proposed. However, existing methods suffer from either the high complexity of genetic algorithms or inaccurate gradient estimation, thus are arduous to obtain adversarial examples with high semantic similarity and low perturbation rate under the tight-budget scenario. In this paper, we propose a simple and sweet paradigm for hard-label textual adversarial attack, named SSPAttack. Specifically, SSPAttack first utilizes initialization to generate an adversarial example, and removes unnecessary replacement words to reduce the number of changed words. Then it determines the replacement order and searches for an anchor synonym, thus avoiding going through all the synonyms. Finally, it pushes substitution words towards original words until an appropriate adversarial example is obtained. The core idea of SSPAttack is just swapping words whose mechanism is simple. Experimental results on eight benchmark datasets and two real-world APIs have shown that the performance of SSPAttack is sweet in terms of similarity, perturbation rate and query efficiency.},
	booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence},
	articleno = {1484},
	numpages = {8},
	selected = true, 
	series = {AAAI'23/IAAI'23/EAAI'23}
}

@inproceedings{10.1609/aaai.v37i11.26552,
	author = {Liu, Han and Zhang, Feng and Zhang, Xiaotong and Zhao, Siyang and Ma, Fenglong and Wu, Xiao-Ming and Chen, Hongyang and Yu, Hong and Zhang, Xianchao},
	title = {Boosting few-shot text classification via distribution estimation},
	year = {2023},
	isbn = {978-1-57735-880-0},
	publisher = {AAAI Press},
	url = {https://doi.org/10.1609/aaai.v37i11.26552},
	doi = {10.1609/aaai.v37i11.26552},
	abstract = {Distribution estimation has been demonstrated as one of the most effective approaches in dealing with few-shot image classification, as the low-level patterns and underlying representations can be easily transferred across different tasks in computer vision domain. However, directly applying this approach to few-shot text classification is challenging, since leveraging the statistics of known classes with sufficient samples to calibrate the distributions of novel classes may cause negative effects due to serious category difference in text domain. To alleviate this issue, we propose two simple yet effective strategies to estimate the distributions of the novel classes by utilizing unlabeled query samples, thus avoiding the potential negative transfer issue. Specifically, we first assume a class or sample follows the Gaussian distribution, and use the original support set and the nearest few query samples to estimate the corresponding mean and covariance. Then, we augment the labeled samples by sampling from the estimated distribution, which can provide sufficient supervision for training the classification model. Extensive experiments on eight few-shot text classification datasets show that the proposed method outperforms state-of-the-art baselines significantly.},
	booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence},
	articleno = {1483},
	numpages = {9},
	selected = true,
	series = {AAAI'23/IAAI'23/EAAI'23}
}

@article{10.1145/3588922,
	author = {Liao, Meihao and Li, Rong-Hua and Dai, Qiangqiang and Chen, Hongyang and Qin, Hongchao and Wang, Guoren},
	title = {Efficient Resistance Distance Computation: The Power of Landmark-based Approaches},
	year = {2023},
	issue_date = {May 2023},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {1},
	number = {1},
	url = {https://doi.org/10.1145/3588922},
	doi = {10.1145/3588922},
	abstract = {Resistance distance is a fundamental metric to measure the similarity between two nodes in graphs which has been widely used in many real-world applications. In this paper, we study two problems on approximately computing resistance distance: (i) single-pair query which aims at calculating the resistance distance r(s, t) for a given pair of nodes (s, t); and (ii) single-source query which is to compute all the resistance distances r(s, u) for all nodes u in the graph with a given source node s. Existing algorithms for these two resistance distance query problems are often costly on large graphs. To efficiently solve these problems, we first establish several interesting connections among resistance distance, a new concept called v-absorbed random walk, random spanning forests, and a newly-developed v-absorbed push procedure. Based on such new connections, we propose three novel and efficient sampling-based algorithms as well as a deterministic algorithm for single-pair query; and we develop an online and two index-based approximation algorithms for single-source query. We show that the two index-based algorithms for single-source query take almost the same running time as the algorithms for single-pair query with the aid of a linear-size index. The striking feature of all our algorithms is that they are allowed to select an easy-to-hit node by random walks on the graph. Such an easy-to-hit landmark node v can make the v-absorbed random walk sampling, spanning tree sampling, as well as the v-absorbed push more efficient, thus significantly improving the performance of our algorithms. Extensive experiments on 5 real-life datasets show that our algorithms substantially outperform the state-of-the-art algorithms for two resistance distance query problems in terms of both running time and estimation errors.},
	journal = {Proc. ACM Manag. Data},
	month = {may},
	articleno = {68},
	numpages = {27},
	keywords = {approximate algorithm, graph proximity, resistance distance},
	selected = true
}
